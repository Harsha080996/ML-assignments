{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsha080996/ML-assignments/blob/master/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vzrrOuJz1jcR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CREATING CONVULTION NETWORK FOR CIFAR 10 DATASET**"
      ]
    },
    {
      "metadata": {
        "id": "fw160qdurjDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "879fc6f7-05a5-4145-fd85-9222c94c91e5"
      },
      "cell_type": "code",
      "source": [
        "#importing required headers and libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cx7K9M-Ltyr2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading CIFAR-10 data set and dividing the samples into train samples and test samples**"
      ]
    },
    {
      "metadata": {
        "id": "xlWmVOhtw4yN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3cda4107-1ad4-4138-c945-f93852f7a804"
      },
      "cell_type": "code",
      "source": [
        "batchsize = 32\n",
        "total_classes = 10\n",
        "Epoch = 100\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "#loading CIFAR-10 dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "#Now we need to divide total samples into train and test samples\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "#one hot encoding needs to be done to make sure we have 1 for the digit and rest should be 0's in the vector\n",
        "Y_train = np_utils.to_categorical(Y_train, total_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, total_classes)\n",
        "\n",
        "X_train = list(X_train)\n",
        "Y_train = list(Y_train)\n",
        "\n",
        "new_x = np.array(X_train[4*10000:(4+1)*10000])\n",
        "new_y = np.array(Y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_train = np.array(X_train[0:4*10000]+X_train[(4+1)*10000:50000])\n",
        "y_train = np.array(Y_train[0:4*10000]+Y_train[(4+1)*10000:50000])\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 24s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qBxRgL7o8Syj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation**"
      ]
    },
    {
      "metadata": {
        "id": "-teMU21J8QVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_augmentation(x,y,new_x):\n",
        "  #Data Augmentation parameters are listed below\n",
        "  datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False,  zca_whitening=False, \n",
        "  zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.1,height_shift_range=0.1,shear_range=0.,zoom_range=0., channel_shift_range=0.,fill_mode='nearest',\n",
        "  cval=0., horizontal_flip=True, vertical_flip=False, rescale=None,preprocessing_function=None,data_format=None,validation_split=0.0)\n",
        "  \n",
        "  datagen.fit(new_x)\n",
        "  #The augmented images are trained statically\n",
        "  for a in range(10):\n",
        "    num_batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x, y, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        num_batches += 1\n",
        "        if num_batches >= 1:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XcgOC5f22Ye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training on First Architecture**"
      ]
    },
    {
      "metadata": {
        "id": "n0vCcCVAsm53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "3818b7f7-0a1c-4144-d3a7-e86634f616fb"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "#Traning augmented images and displaying their loss and accuracy values\n",
        "data_augmentation(x_train,y_train,x_train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 241s 6ms/step - loss: 1.8924 - acc: 0.2893\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 240s 6ms/step - loss: 1.6035 - acc: 0.4047\n",
            "Epoch 1/1\n",
            "39392/40000 [============================>.] - ETA: 3s - loss: 1.4824 - acc: 0.4589"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mJZUzOJrETp4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fitting the training data for first architecture and displaying the loss and accuracy**"
      ]
    },
    {
      "metadata": {
        "id": "VvTwGlm6EUGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(new_x, new_y))\n",
        "result = model.evaluate(new_x, new_y, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', result[0])\n",
        "print('accuracy for test data:', result[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VcLEIcspBX4F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting the accuracy graph for first architecture\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pfMppZTqt2xB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training on second architecture**"
      ]
    },
    {
      "metadata": {
        "id": "ocXbpqsbt3L7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(total_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "#Traning augmented images and displaying their loss and accuracy values for second architecture\n",
        "data_augmentation(x_train,y_train,x_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YvqBqoXGIEbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fitting the training data for second architecture and displaying the loss and accuracy\n",
        "history = model.fit(x_train, y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(new_x, new_y))\n",
        "result = model.evaluate(new_x, new_y, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', result[0])\n",
        "print('accuracy for test data:', result[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6QhfPVIIEzy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting the accuracy graph for second architecture\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUeD-3GTt3cF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training on third architecture**\n"
      ]
    },
    {
      "metadata": {
        "id": "0yNKGPb4t3zL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "#Traning augmented images and displaying their loss and accuracy values for third architecture\n",
        "data_augmentation(x_train,y_train,x_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jsU18yXCKOUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fitting the training data for third architecture and displaying the loss and accuracy\n",
        "history = model.fit(x_train, y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(new_x, new_y))\n",
        "result = model.evaluate(new_x, new_y, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', result[0])\n",
        "print('accuracy for test data:', result[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_4SrvGgKOhp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting the accuracy graph for third architecture\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnHOpiAKt4FD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training on fourth architecture**"
      ]
    },
    {
      "metadata": {
        "id": "elpl0Wilt4UZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "#Traning augmented images and displaying their loss and accuracy values for fourth architecture\n",
        "data_augmentation(x_train,y_train,x_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BvTIIUL2N-YE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fitting the training data for fourth architecture and displaying the loss and accuracy\n",
        "history = model.fit(x_train, y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(new_x, new_y))\n",
        "result = model.evaluate(new_x, new_y, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', result[0])\n",
        "print('accuracy for test data:', result[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vC0bWDwsN-tA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting the accuracy graph for fourth architecture\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddEFFQ6yt4sE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The best architecture among all is architecture four. Training fourth architecture on data from training set and validation set and evaluationg its performance on test set**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Hgedqe5Tt48_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "\n",
        "#Traning augmented images and displaying their loss and accuracy values for fourth architecture by training fourth architecture on data from training set and validation set and evaluationg its performance on test set\n",
        "\n",
        "data_augmentation(X_train, Y_train, X_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ventnVpRSBuj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fitting the training data for fourth architecture and displaying the loss and accuracy by training fourth architecture on data from training set and validation set and evaluationg its performance on test set\n",
        "\n",
        "history = model.fit(X_train, Y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(X_test, Y_test))\n",
        "result = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', result[0])\n",
        "print('accuracy for test data:', result[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "saSGePd0SB_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting the accuracy graph\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4mbFeqht5Mc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Re-evaluating fourth architecture using k-fold validation with k=5**"
      ]
    },
    {
      "metadata": {
        "id": "z0zKk7zrt5hi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  new_x = np.array(X_train[i*10000:(i+1)*10000])\n",
        "  new_y = np.array(Y_train[i*10000:(i+1)*10000])\n",
        "  x_train = np.array(X_train[0:i*10000]+X_train[(i+1)*10000:50000])\n",
        "  y_train = np.array(Y_train[0:i*10000]+Y_train[(i+1)*10000:50000])\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(128, (2, 2)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "  #Traning augmented images and displaying their loss and accuracy values for k-fold cross validation with k=5\n",
        "  data_augmentation(x_train, y_train, x_train)\n",
        "  \n",
        "loss_avg = 0\n",
        "acc_avg = 0\n",
        "for i in range(5):\n",
        "  loss_avg += val_loss[i]/5\n",
        "  acc_avg += val_acc[i]/5\n",
        "  \n",
        "print('avgerage validation loss:',loss_avg)\n",
        "print('average validation accuracy:',acc_Avg))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5whO9C8cU2A0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fitting the training data for above architecture which uses k-fold cross validation and displaying the loss and accuracy\n",
        "history = model.fit(x_train, y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(new_x, new_y))\n",
        "result = model.evaluate(new_x, new_y, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('avg. loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('avg. accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', result[0])\n",
        "print('accuracy for test data:', result[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ecjAn_RHU2Rp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting the accuracy graph\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}