{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsha080996/ML-assignments/blob/master/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vzrrOuJz1jcR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CREATING CONVULTION NETWORK FOR CIFAR 10 DATASET**"
      ]
    },
    {
      "metadata": {
        "id": "fw160qdurjDT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing required headers and libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cx7K9M-Ltyr2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading CIFAR-10 data set and dividing the samples into train samples and test samples**"
      ]
    },
    {
      "metadata": {
        "id": "xlWmVOhtw4yN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchsize = 32\n",
        "total_classes = 10\n",
        "Epoch = 5\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "#loading CIFAR-10 dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "#Now we need to divide total samples into train and test samples\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "#one hot encoding needs to be done to make sure we have 1 for the digit and rest should be 0's in the vector\n",
        "Y_train = np_utils.to_categorical(Y_train, total_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, total_classes)\n",
        "\n",
        "X_train = list(X_train)\n",
        "Y_train = list(Y_train)\n",
        "\n",
        "new_x = np.array(X_train[4*10000:(4+1)*10000])\n",
        "new_y = np.array(Y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_train = np.array(X_train[0:4*10000]+X_train[(4+1)*10000:50000])\n",
        "y_train = np.array(Y_train[0:4*10000]+Y_train[(4+1)*10000:50000])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBxRgL7o8Syj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation**"
      ]
    },
    {
      "metadata": {
        "id": "-teMU21J8QVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_augmentation(x,y):\n",
        "  #Data Augmentation parameters are listed below\n",
        "  datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False,  zca_whitening=False, \n",
        "  zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.1,height_shift_range=0.1,shear_range=0.,zoom_range=0., channel_shift_range=0.,fill_mode='nearest',\n",
        "  cval=0., horizontal_flip=True, vertical_flip=False, rescale=None,preprocessing_function=None,data_format=None,validation_split=0.0)\n",
        "  \n",
        "  datagen.fit(x_train)\n",
        "  #The augmented images are trained statically\n",
        "  for a in range(10):\n",
        "    num_batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x, y, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        num_batches += 1\n",
        "        if num_batches >= 1:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XcgOC5f22Ye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training on First Architecture**"
      ]
    },
    {
      "metadata": {
        "id": "n0vCcCVAsm53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "3e000ac6-654b-4ba2-98d5-76f56a4d7630"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "#Traning augmented images and displaying their loss and accuracy values\n",
        "data_augmentation(x_train,y_train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 255s 6ms/step - loss: 1.8921 - acc: 0.2912\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 256s 6ms/step - loss: 1.5854 - acc: 0.4168\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 253s 6ms/step - loss: 1.4505 - acc: 0.4724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mJZUzOJrETp4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fitting the training data for first architecture and displaying the loss and accuracy**"
      ]
    },
    {
      "metadata": {
        "id": "VvTwGlm6EUGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(new_x, new_y))\n",
        "result = model.evaluate(new_x, new_y, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', score[0])\n",
        "print('accuracy for test data:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VcLEIcspBX4F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting the accuracy graph for first architecture\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pfMppZTqt2xB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training on second architecture**"
      ]
    },
    {
      "metadata": {
        "id": "ocXbpqsbt3L7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(total_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "##Traning augmented images and displaying their loss and accuracy values for second architecture\n",
        "data_augmentation(x_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YvqBqoXGIEbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fitting the training data for second architecture and displaying the loss and accuracy\n",
        "history = model.fit(x_train, y_train,batch_size=batchsize,epochs=Epoch,verbose=1,validation_data=(new_x, new_y))\n",
        "result = model.evaluate(new_x, new_y, verbose=0)\n",
        "print(result)\n",
        "print(history.history)\n",
        "print('loss for validation data is:',history.history['val_loss'][-1])\n",
        "print('accuracy for validation data is:',history.history['val_acc'][-1])\n",
        "print('loss for test data:', score[0])\n",
        "print('accuracy for test data:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6QhfPVIIEzy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##plotting the accuracy graph for first architecture\n",
        "plotaccuracy = plt.plot(range(1,Epoch+1),history.history['acc'],range(1,Epoch+1),history.history['val_acc'])\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUeD-3GTt3cF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training on third architecture**"
      ]
    },
    {
      "metadata": {
        "id": "0yNKGPb4t3zL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_tra.shape[1:]))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('validation loss:',History.history['val_loss'][-1])\n",
        "print('validation accuracy:',History.history['val_acc'][-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnHOpiAKt4FD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "elpl0Wilt4UZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('validation loss:',History.history['val_loss'][-1])\n",
        "print('validation accuracy:',History.history['val_acc'][-1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddEFFQ6yt4sE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Hgedqe5Tt48_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=50000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('Test loss:',History.history['val_loss'][-1])\n",
        "print('Test accuracy:',History.history['val_acc'][-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4mbFeqht5Mc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "z0zKk7zrt5hi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i in range(5):\n",
        "  x_val = np.array(x_train[i*10000:(i+1)*10000])\n",
        "  y_val = np.array(y_train[i*10000:(i+1)*10000])\n",
        "  \n",
        "  x_tra = np.array(x_train[0:i*10000]+x_train[(i+1)*10000:50000])\n",
        "  y_tra = np.array(y_train[0:i*10000]+y_train[(i+1)*10000:50000])\n",
        "  \n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(128, (2, 2)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "  datagen.fit(x_tra)\n",
        "\n",
        "  for e in range(10):\n",
        "      batches = 0\n",
        "      for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=50000):\n",
        "          model.fit(x_batch, y_batch)\n",
        "          batches += 1\n",
        "          if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "              break\n",
        "\n",
        "  \n",
        "  History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "  score = model.evaluate(x_val, y_val, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  print(score)\n",
        "  print(History.history)\n",
        "\n",
        "  plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "  plt.show(plotaccuracy)\n",
        "  \n",
        "  val_loss.append(History.history['val_loss'][-1])\n",
        "  val_acc.append(History.history['val_acc'][-1])\n",
        "\n",
        "avg_val_loss = 0\n",
        "avg_val_acc = 0\n",
        "for i in range(5):\n",
        "  avg_val_loss += val_loss[i]/5\n",
        "  avg_val_acc += val_acc[i]/5\n",
        "  \n",
        "print('avgerage validation loss:',avg_val_loss)\n",
        "print('average validation accuracy:',avg_val_acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}