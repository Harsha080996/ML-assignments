{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problem4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsha080996/ML-assignments/blob/master/HW1problem5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6Ijq0AcJjbm7",
        "colab_type": "code",
        "outputId": "4cf4be1b-efc9-43ff-d520-81aef29f8b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2031
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#Loading the MNIST data and classifying data into test and train set\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "input_dim = 784 #enter input dimesions for the image 28*28\n",
        "output_dim = 10\n",
        "total_classes = 10\n",
        "batch_size = 128\n",
        "epoch_value = 50 #number of times experiment runs\n",
        "train_components = list()\n",
        "test_components = list()\n",
        "for i in range(60000):#Filtering based on white spaces in MNIST train data\n",
        "  if Y_train[i] in [1,2,3,4,5,7]:\n",
        "    train_components.append(1/3)\n",
        "  elif Y_train[i] in [0,6,9]:\n",
        "    train_components.append(2/3)\n",
        "  elif Y_train[i] == 8:\n",
        "    train_components.append(1)\n",
        "    \n",
        "for i in range(10000):#Filtering based on white spaces in MNIST test data\n",
        "  if Y_test[i] in [1,2,3,4,5,7]:\n",
        "    test_components.append(1/3)\n",
        "  elif Y_test[i] in [0,6,9]:\n",
        "    test_components.append(2/3)\n",
        "  elif Y_test[i] == 8:\n",
        "    test_components.append(1)\n",
        "\n",
        "#we are calculating the height and width of training and test images\n",
        "train_row = np.sum(X_train, axis = 1, keepdims = True)\n",
        "test_row = np.sum(X_test, axis = 1 , keepdims = True)\n",
        "train_column = np.sum(X_train, axis = 2, keepdims = True)\n",
        "test_column = np.sum(X_test, axis = 2, keepdims = True)\n",
        "train_width = list()\n",
        "train_height = list()\n",
        "test_height = list()\n",
        "test_width = list()\n",
        "for i in range(60000):\n",
        "  count1,count2 = 0,0\n",
        "  for j in range(28):\n",
        "    if train_row[i][0][j] > 0:count1 += 1\n",
        "    if train_column[i][j][0] > 0:count2 += 1\n",
        "  train_width.append(count1/28)\n",
        "  train_height.append(count2/28)\n",
        "test_width = list()\n",
        "for i in range(10000):\n",
        "  count = 0\n",
        "  for j in range(28):\n",
        "    if test_row[i][0][j] > 0:count1 += 1\n",
        "    if test_column[i][j][0] > 0:count2 += 1\n",
        "  test_width.append(count1/28)\n",
        "  test_height.append(count2/28)\n",
        "\n",
        "\n",
        "# We are adding additional feature where we count number of white spaces in training and test data and add them to the model\n",
        "train_white = list()\n",
        "for i in range(60000):\n",
        "  a = 0\n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      if X_train[i][j][k] == 0:\n",
        "        a += 1\n",
        "  train_white.append(1-(a/input_dim))\n",
        "  \n",
        "test_white = list()\n",
        "for i in range(10000):\n",
        "  a = 0\n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      if X_test[i][j][k] == 0:\n",
        "        a += 1\n",
        "  test_white.append(1-(a/input_dim))\n",
        "  \n",
        "#Reshape X_test and X_train values\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "#Now we divide all values with 255 to make sure that all values are with in 0 and 1\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "#concatenating the additional features to our model\n",
        "x_train = np.zeros((X_train.shape[0],X_train.shape[1]+4))\n",
        "x_test = np.zeros((X_test.shape[0],X_test.shape[1]+4))\n",
        "\n",
        "#Adding training set features\n",
        "for i in range(X_train.shape[0]):\n",
        "  for j in range(input_dim):\n",
        "    x_train[i][j] = X_train[i][j]\n",
        "  x_train[i][X_train.shape[1]] = train_components[i]\n",
        "  x_train[i][X_train.shape[1]+1] = train_width[i]\n",
        "  x_train[i][X_train.shape[1]+2] = train_height[i]\n",
        "  x_train[i][X_train.shape[1]+3] = train_white[i]\n",
        "#Adding test set features\n",
        "for i in range(X_test.shape[0]):\n",
        "  for j in range(input_dim):\n",
        "    x_test[i][j] = X_test[i][j]\n",
        "  x_test[i][X_test.shape[1]] = test_components[i]\n",
        "  x_test[i][X_test.shape[1]+1] = test_width[i]\n",
        "  x_test[i][X_test.shape[1]+2] = test_height[i]\n",
        "  x_test[i][X_test.shape[1]+3] = test_white[i]\n",
        "#one hot encoding needs to be done to make sure we have 1 for the digit and rest should be 0's in the vector\n",
        "Y_train = np_utils.to_categorical(Y_train, total_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, total_classes)\n",
        "model = Sequential() \n",
        "#Now we add the softmax as activation function and compile the model\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "model.compile(optimizer=keras.optimizers.SGD(lr=0.05), loss= keras.losses.categorical_crossentropy, metrics=['accuracy'])#calling sgd, categorical cross entropy functions and accuracy from keras\n",
        "history = model.fit(x_train, Y_train, batch_size = batch_size, nb_epoch = epoch_value,verbose=1, validation_data=(x_test, Y_test))#Training the test set and train set using keras\n",
        "score = model.evaluate(x_test, Y_test, verbose=0)#evaluating the results for the test set\n",
        "print('Test loss is', score[0])\n",
        "print('Test accuracy is', score[1]*100,'%')#printing the accuracy\n",
        "print(history.history)\n",
        "print(score)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:115: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.7140 - acc: 0.8310 - val_loss: 14.2108 - val_acc: 0.0994\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.4137 - acc: 0.8931 - val_loss: 14.5373 - val_acc: 0.0928\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.3608 - acc: 0.9044 - val_loss: 14.5772 - val_acc: 0.0918\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.3324 - acc: 0.9110 - val_loss: 14.5948 - val_acc: 0.0913\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.3131 - acc: 0.9157 - val_loss: 14.6080 - val_acc: 0.0905\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2988 - acc: 0.9198 - val_loss: 14.6155 - val_acc: 0.0905\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2874 - acc: 0.9230 - val_loss: 14.6221 - val_acc: 0.0904\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2781 - acc: 0.9256 - val_loss: 14.6281 - val_acc: 0.0903\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2701 - acc: 0.9279 - val_loss: 14.6309 - val_acc: 0.0903\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2633 - acc: 0.9298 - val_loss: 14.6357 - val_acc: 0.0902\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2572 - acc: 0.9312 - val_loss: 14.6397 - val_acc: 0.0900\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2518 - acc: 0.9326 - val_loss: 14.6423 - val_acc: 0.0900\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2469 - acc: 0.9341 - val_loss: 14.6441 - val_acc: 0.0900\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2426 - acc: 0.9353 - val_loss: 14.6461 - val_acc: 0.0900\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2386 - acc: 0.9361 - val_loss: 14.6477 - val_acc: 0.0900\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2348 - acc: 0.9371 - val_loss: 14.6497 - val_acc: 0.0900\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2314 - acc: 0.9380 - val_loss: 14.6501 - val_acc: 0.0900\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2281 - acc: 0.9390 - val_loss: 14.6512 - val_acc: 0.0900\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2251 - acc: 0.9398 - val_loss: 14.6523 - val_acc: 0.0900\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2224 - acc: 0.9407 - val_loss: 14.6532 - val_acc: 0.0900\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2198 - acc: 0.9411 - val_loss: 14.6539 - val_acc: 0.0900\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2173 - acc: 0.9424 - val_loss: 14.6547 - val_acc: 0.0900\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2149 - acc: 0.9427 - val_loss: 14.6553 - val_acc: 0.0900\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2126 - acc: 0.9436 - val_loss: 14.6558 - val_acc: 0.0899\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2106 - acc: 0.9436 - val_loss: 14.6561 - val_acc: 0.0900\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2086 - acc: 0.9446 - val_loss: 14.6566 - val_acc: 0.0899\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2067 - acc: 0.9449 - val_loss: 14.6571 - val_acc: 0.0899\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2048 - acc: 0.9455 - val_loss: 14.6576 - val_acc: 0.0899\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2031 - acc: 0.9460 - val_loss: 14.6577 - val_acc: 0.0899\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2014 - acc: 0.9464 - val_loss: 14.6580 - val_acc: 0.0899\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1998 - acc: 0.9472 - val_loss: 14.6585 - val_acc: 0.0899\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1982 - acc: 0.9470 - val_loss: 14.6584 - val_acc: 0.0899\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1967 - acc: 0.9482 - val_loss: 14.6588 - val_acc: 0.0899\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1953 - acc: 0.9482 - val_loss: 14.6588 - val_acc: 0.0899\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1939 - acc: 0.9486 - val_loss: 14.6593 - val_acc: 0.0899\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1926 - acc: 0.9491 - val_loss: 14.6594 - val_acc: 0.0899\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1912 - acc: 0.9499 - val_loss: 14.6595 - val_acc: 0.0899\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1900 - acc: 0.9498 - val_loss: 14.6595 - val_acc: 0.0899\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1888 - acc: 0.9501 - val_loss: 14.6597 - val_acc: 0.0899\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1875 - acc: 0.9505 - val_loss: 14.6602 - val_acc: 0.0899\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1865 - acc: 0.9508 - val_loss: 14.6600 - val_acc: 0.0899\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1854 - acc: 0.9510 - val_loss: 14.6602 - val_acc: 0.0899\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1843 - acc: 0.9514 - val_loss: 14.6604 - val_acc: 0.0899\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1832 - acc: 0.9519 - val_loss: 14.6603 - val_acc: 0.0899\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1822 - acc: 0.9519 - val_loss: 14.6606 - val_acc: 0.0899\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1812 - acc: 0.9523 - val_loss: 14.6604 - val_acc: 0.0899\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1802 - acc: 0.9524 - val_loss: 14.6608 - val_acc: 0.0899\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1793 - acc: 0.9527 - val_loss: 14.6607 - val_acc: 0.0899\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1784 - acc: 0.9530 - val_loss: 14.6610 - val_acc: 0.0899\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1776 - acc: 0.9533 - val_loss: 14.6608 - val_acc: 0.0899\n",
            "Test loss is 14.660818028259277\n",
            "Test accuracy is 8.99 %\n",
            "{'val_loss': [14.210816792297363, 14.53731954498291, 14.57717509918213, 14.594770533752442, 14.60798722076416, 14.615533045959472, 14.622084083557128, 14.628083619689942, 14.63090627593994, 14.635657838439942, 14.639662831115723, 14.64225705718994, 14.644098402404785, 14.64605763092041, 14.647732704162598, 14.649714125061035, 14.650146522521972, 14.651200538635253, 14.65230986480713, 14.653207643127441, 14.653870375061036, 14.654681520080567, 14.65529257965088, 14.655838356018066, 14.656091407775879, 14.656551405334472, 14.65709629058838, 14.657583351135253, 14.657690675354004, 14.657959620666503, 14.658479774475097, 14.658407801818848, 14.658830653381347, 14.658839039611816, 14.659253370666503, 14.659367481994629, 14.659532862854004, 14.659522816467286, 14.659710304260255, 14.660157569885254, 14.660022010803223, 14.660165065002442, 14.660413575744629, 14.660278517150878, 14.660615943908692, 14.660433937072755, 14.660782887268066, 14.660728297424317, 14.660960792541504, 14.66082138824463], 'val_acc': [0.0994, 0.0928, 0.0918, 0.0913, 0.0905, 0.0905, 0.0904, 0.0903, 0.0903, 0.0902, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.0899, 0.09, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899, 0.0899], 'loss': [0.7140040847619374, 0.4137211476961772, 0.36084052387873333, 0.3324217574755351, 0.3130689995765686, 0.29875702785650887, 0.28738599298795064, 0.27808480554421744, 0.2700698254108429, 0.26333930346171064, 0.2572300026337306, 0.25182618454297384, 0.2468932675520579, 0.24257099202473958, 0.23857157705624898, 0.23476693028608958, 0.23135682975451152, 0.22812705639998118, 0.22512540033658346, 0.22244869089921315, 0.2198480009317398, 0.2172745845158895, 0.21489482652346292, 0.21261019744873047, 0.21064821303685508, 0.20860050396124521, 0.2066715611855189, 0.20478670535087584, 0.2031371037085851, 0.20139377969106037, 0.19981410018603007, 0.19819868418375652, 0.19670502543449403, 0.19533073681195576, 0.19390294059514998, 0.19256122602621714, 0.19124342169761657, 0.19000812411308288, 0.18882409853935242, 0.1874855476617813, 0.18647541449864705, 0.1853507140159607, 0.18431340250174205, 0.18323579145272573, 0.18219598333040873, 0.1812133214155833, 0.1802380074898402, 0.17931569938659667, 0.17842287453015646, 0.17755523853302002], 'acc': [0.8309833333333333, 0.8930500000317891, 0.9043666666984558, 0.9109666666666667, 0.9156666666666666, 0.91985, 0.9229833333015441, 0.9256166666348775, 0.9279, 0.9298166666348775, 0.9311833333651225, 0.9326, 0.9340833333015441, 0.9353, 0.9361166666984558, 0.9370500000317892, 0.9380333333333334, 0.9390166666666667, 0.9397666666348775, 0.9406666666666667, 0.9411333333333334, 0.9424166666984558, 0.9426666666984558, 0.9436499999682109, 0.94365, 0.9445833333015442, 0.9448500000317891, 0.9454833333015442, 0.9460333333015442, 0.9463666666984558, 0.9472000000317892, 0.94705, 0.9482166666348775, 0.9482499999682109, 0.9485500000317891, 0.9491000000317892, 0.9499166666348775, 0.9497833333333333, 0.9501166666984558, 0.9504666666348776, 0.9508333333333333, 0.9510000000317892, 0.9514, 0.9518999999682108, 0.95195, 0.9523333333333334, 0.9524166666348776, 0.9526833333015442, 0.9529833333015442, 0.9533333333015442]}\n",
            "[14.660818028259277, 0.0899]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n3ZpGyyeC9F7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "53f3dc02-1255-47a5-bda5-f2c3235c4cdd"
      },
      "cell_type": "code",
      "source": [
        "#plotting in the graph\n",
        "plotaccuracy = plt.plot(range(1,51),history.history['acc'],range(1,51),history.history['val_acc'])\n",
        "plt.xlabel('epoch_values')\n",
        "plt.ylabel('accuracy_level')\n",
        "plt.legend(('Training set Accuracy','Test set Accuracy'))\n",
        "plt.show(plotaccuracy)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}