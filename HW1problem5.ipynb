{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problem4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsha080996/ML-assignments/blob/master/HW1problem5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6Ijq0AcJjbm7",
        "colab_type": "code",
        "outputId": "4cf4be1b-efc9-43ff-d520-81aef29f8b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#Loading the MNIST data and classifying data into test and train set\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "input_dim = 784 #enter input dimesions for the image 28*28\n",
        "output_dim = 10\n",
        "total_classes = 10\n",
        "batch_size = 128\n",
        "epoch_value = 50 #number of times experiment runs\n",
        "train_components = list()\n",
        "test_components = list()\n",
        "for i in range(60000):#Filtering based on white spaces in MNIST train data\n",
        "  if Y_train[i] in [1,2,3,4,5,7]:\n",
        "    train_components.append(1/3)\n",
        "  elif Y_train[i] in [0,6,9]:\n",
        "    train_components.append(2/3)\n",
        "  elif Y_train[i] == 8:\n",
        "    train_components.append(1)\n",
        "    \n",
        "for i in range(10000):#Filtering based on white spaces in MNIST test data\n",
        "  if Y_test[i] in [1,2,3,4,5,7]:\n",
        "    test_components.append(1/3)\n",
        "  elif Y_test[i] in [0,6,9]:\n",
        "    test_components.append(2/3)\n",
        "  elif Y_test[i] == 8:\n",
        "    test_components.append(1)\n",
        "\n",
        "#we are calculating the height and width of training and test images\n",
        "train_row = np.sum(X_train, axis = 1, keepdims = True)\n",
        "test_row = np.sum(X_test, axis = 1 , keepdims = True)\n",
        "train_column = np.sum(X_train, axis = 2, keepdims = True)\n",
        "test_column = np.sum(X_test, axis = 2, keepdims = True)\n",
        "train_width = list()\n",
        "train_height = list()\n",
        "test_height = list()\n",
        "test_width = list()\n",
        "for i in range(60000):\n",
        "  count1,count2 = 0,0\n",
        "  for j in range(28):\n",
        "    if train_row[i][0][j] > 0:count1 += 1\n",
        "    if train_column[i][j][0] > 0:count2 += 1\n",
        "  train_width.append(count1/28)\n",
        "  train_height.append(count2/28)\n",
        "test_width = list()\n",
        "for i in range(10000):\n",
        "  count = 0\n",
        "  for j in range(28):\n",
        "    if test_row[i][0][j] > 0:count1 += 1\n",
        "    if test_column[i][j][0] > 0:count2 += 1\n",
        "  test_width.append(count1/28)\n",
        "  test_height.append(count2/28)\n",
        "\n",
        "\n",
        "# We are adding additional feature where we count number of white spaces in training and test data and add them to the model\n",
        "train_white = list()\n",
        "for i in range(60000):\n",
        "  a = 0\n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      if X_train[i][j][k] == 0:\n",
        "        a += 1\n",
        "  train_white.append(1-(a/input_dim))\n",
        "  \n",
        "test_white = list()\n",
        "for i in range(10000):\n",
        "  a = 0\n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      if X_test[i][j][k] == 0:\n",
        "        a += 1\n",
        "  test_white.append(1-(a/input_dim))\n",
        "  \n",
        "#Reshape X_test and X_train values\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "#Now we divide all values with 255 to make sure that all values are with in 0 and 1\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "#concatenating the additional features to our model\n",
        "x_train = np.zeros((X_train.shape[0],X_train.shape[1]+4))\n",
        "x_test = np.zeros((X_test.shape[0],X_test.shape[1]+4))\n",
        "\n",
        "#Adding training set features\n",
        "for i in range(X_train.shape[0]):\n",
        "  for j in range(input_dim):\n",
        "    x_train[i][j] = X_train[i][j]\n",
        "  x_train[i][X_train.shape[1]] = train_components[i]\n",
        "  x_train[i][X_train.shape[1]+1] = train_width[i]\n",
        "  x_train[i][X_train.shape[1]+2] = train_height[i]\n",
        "  x_train[i][X_train.shape[1]+3] = train_white[i]\n",
        "#Adding test set features\n",
        "for i in range(X_test.shape[0]):\n",
        "  for j in range(input_dim):\n",
        "    x_test[i][j] = X_test[i][j]\n",
        "  x_test[i][X_test.shape[1]] = test_components[i]\n",
        "  x_test[i][X_test.shape[1]+1] = test_width[i]\n",
        "  x_test[i][X_test.shape[1]+2] = test_height[i]\n",
        "  x_test[i][X_test.shape[1]+3] = test_white[i]\n",
        "#one hot encoding needs to be done to make sure we have 1 for the digit and rest should be 0's in the vector\n",
        "Y_train = np_utils.to_categorical(Y_train, total_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, total_classes)\n",
        "model = Sequential() \n",
        "#Now we add the softmax as activation function and compile the model\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "model.compile(optimizer=keras.optimizers.SGD(lr=0.05), loss= keras.losses.categorical_crossentropy, metrics=['accuracy'])#calling sgd, categorical cross entropy functions and accuracy from keras\n",
        "history = model.fit(x_train, Y_train, batch_size = batch_size, nb_epoch = epoch_value,verbose=1, validation_data=(x_test, Y_test))#Training the test set and train set using keras\n",
        "score = model.evaluate(x_test, Y_test, verbose=0)#evaluating the results for the test set\n",
        "print('Test loss is', score[0])\n",
        "print('Test accuracy is', score[1]*100,'%')#printing the accuracy\n",
        "print(history.history)\n",
        "print(score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n3ZpGyyeC9F7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plotting in the graph\n",
        "plotaccuracy = plt.plot(range(1,51),history.history['acc'],range(1,51),history.history['val_acc'])\n",
        "plt.xlabel('epoch_values')\n",
        "plt.ylabel('accuracy_level')\n",
        "plt.legend(('Training set Accuracy','Test set Accuracy'))\n",
        "plt.show(plotaccuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}